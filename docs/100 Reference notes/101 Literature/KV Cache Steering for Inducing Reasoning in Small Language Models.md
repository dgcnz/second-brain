---
authors:
  - "[[Max Belitsky|Max Belitsky]]"
  - "[[Dawid J. Kopiczko|Dawid J. Kopiczko]]"
  - "[[Michael Dorkenwald|Michael Dorkenwald]]"
  - "[[M. Jehanzeb Mirza|M. Jehanzeb Mirza]]"
  - "[[Cees G. M. Snoek|Cees G. M. Snoek]]"
  - "[[Yuki M. Asano|Yuki M. Asano]]"
year: 2025
tags:
  - paper
  - llm
  - efficient_dl
  - reasoning
url: http://arxiv.org/abs/2507.08799
share: true
---


> [!tldr] Abstract
> We propose cache steering, a lightweight method for implicit steering of language models via a one-shot intervention applied directly to the key-value cache. To validate its effectiveness, we apply cache steering to induce chain-of-thought reasoning in small language models. Our approach leverages GPT-4o-generated reasoning traces to construct steering vectors that shift model behavior toward more explicit, multi-step reasoning without fine-tuning or prompt modifications. Experimental evaluations on diverse reasoning benchmarks demonstrate that cache steering improves both the qualitative structure of model reasoning and quantitative task performance. Compared to prior activation steering techniques that require continuous interventions, our one-shot cache steering offers substantial advantages in terms of hyperparameter stability, inference-time efficiency, and ease of integration, making it a more robust and practical solution for controlled generation.



## Notes

[Zotero Link](zotero://select/library/items/IAPPY5ZP)


