---
authors:
  - "[[Tengda Han|Tengda Han]]"
  - "[[Dilara Gokay|Dilara Gokay]]"
  - "[[Joseph Heyward|Joseph Heyward]]"
  - "[[Chuhan Zhang|Chuhan Zhang]]"
  - "[[Daniel Zoran|Daniel Zoran]]"
  - "[[Viorica Pătrăucean|Viorica Pătrăucean]]"
  - "[[João Carreira|João Carreira]]"
  - "[[Dima Damen|Dima Damen]]"
  - "[[Andrew Zisserman|Andrew Zisserman]]"
year: 2025
tags:
  - paper
  - dl_theory
  - ssl
  - video
url: http://arxiv.org/abs/2504.01961
share: true
---


> [!tldr] Abstract
> We address the challenge of representation learning from a continuous stream of video as input, in a self-supervised manner. This differs from the standard approaches to video learning where videos are chopped and shuffled during training in order to create a non-redundant batch that satisfies the independently and identically distributed (IID) sample assumption expected by conventional training paradigms. When videos are only available as a continuous stream of input, the IID assumption is evidently broken, leading to poor performance. We demonstrate the drop in performance when moving from shuffled to sequential learning on three tasks: the one-video representation learning method DoRA, standard VideoMAE on multi-video datasets, and the task of future video prediction.



## Notes

[Zotero Link](zotero://select/library/items/ETHPH37S)


