---
authors:
  - "[[Xinlong Wang|Xinlong Wang]]"
  - "[[Rufeng Zhang|Rufeng Zhang]]"
  - "[[Chunhua Shen|Chunhua Shen]]"
  - "[[Tao Kong|Tao Kong]]"
  - "[[Lei Li|Lei Li]]"
year: 2021
tags:
  - paper
  - ssl
  - vit
  - contrastive_learning
url: http://arxiv.org/abs/2011.09157
share: true
---


> [!tldr] Abstract
> To date, most existing self-supervised learning methods are designed and optimized for image classiﬁcation. These pre-trained models can be sub-optimal for dense prediction tasks due to the discrepancy between image-level prediction and pixel-level prediction. To ﬁll this gap, we aim to design an effective, dense self-supervised learning method that directly works at the level of pixels (or local features) by taking into account the correspondence between local features. We present dense contrastive learning (DenseCL), which implements self-supervised learning by optimizing a pairwise contrastive (dis)similarity loss at the pixel level between two views of input images.



## Notes

[Zotero Link](zotero://select/library/items/NCYDR2FM)


![[Pasted image 20250310213431.png|Pasted image 20250310213431.png]]

![[Pasted image 20250310213443.png|Pasted image 20250310213443.png]]

