---
authors:
- '[[Alexander Kirillov]]'
- '[[Eric Mintun]]'
- '[[Nikhila Ravi]]'
- '[[Hanzi Mao]]'
- '[[Chloe Rolland]]'
- '[[Laura Gustafson]]'
- '[[Tete Xiao]]'
- '[[Spencer Whitehead]]'
- '[[Alexander C. Berg]]'
- '[[Wan-Yen Lo]]'
- "[[Piotr Doll\xE1r]]"
- '[[Ross Girshick]]'
year: 2023
tags:
- paper
- segmentation
- computer_vision
- foundation_models
url: https://arxiv.org/abs/2304.02643
date: '2023-04-05'
---

> [!tldr] Abstract
> We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at [this https URL](https://segment-anything.com/) to foster research into foundation models for computer vision.


